# Insurance Cost Prediction - Regress√£o com Machine Learning

Projeto de compara√ß√£o de modelos de regress√£o para previs√£o de custos de seguro sa√∫de usando o [Medical Cost Personal Dataset](https://www.kaggle.com/datasets/mirichoi0218/insurance).

## üìå Vis√£o Geral
Este projeto avalia o desempenho de 6 algoritmos de regress√£o para prever o valor do seguro m√©dico individual:

- **Regress√£o Linear**
- **Support Vector Regression (SVR)**
- **√Årvore de Decis√£o**
- **Random Forest**
- **XGBoost**
- **LightGBM**

**Objetivo:** Identificar o modelo mais eficaz para prever o custo do seguro (`charges`) a partir de dados demogr√°ficos e comportamentais.

## üìä Dataset
- **1.338 amostras** e **7 vari√°veis**:
  - `age`: Idade do benefici√°rio
  - `sex`: Sexo (`male`/`female`)
  - `bmi`: √çndice de Massa Corporal
  - `children`: N√∫mero de dependentes
  - `smoker`: Fumante (`yes`/`no`)
  - `region`: Regi√£o (`southwest`, `southeast`, `northwest`, `northeast`)
  - `charges`: Custo do seguro (vari√°vel alvo)
- **Pr√©-processamento:** Codifica√ß√£o de vari√°veis categ√≥ricas em valores num√©ricos.
- Divis√£o treino-teste: **70% treino** | **30% teste**

## üß† Modelos Avaliados

### 1. Regress√£o Linear

`LinearRegression()`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.61 / 0.62*
- Valida√ß√£o cruzada (15 folds): 61.26%
- RMSE (Raiz do erro quadr√°tico m√©dio): 7380.55

### 2. Regress√£o Linear M√∫ltipla

`LinearRegression()`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.74 / 0.75*
- Valida√ß√£o cruzada (15 folds): 74.44%
- RMSE (Raiz do erro quadr√°tico m√©dio): 6017.57
- 
### 3. Support Vector Regression (SVR)

`SVR(kernel='rbf')`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.86 / 0.84*
- Valida√ß√£o cruzada (15 folds): 84.46%
- RMSE (Raiz do erro quadr√°tico m√©dio): 4792.53

### 4. √Årvore de Decis√£o

`DecisionTreeRegressor(max_depth=4, random_state=7)`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.87 / 0.85*
- Valida√ß√£o cruzada (15 folds): 84.98%
- RMSE (Raiz do erro quadr√°tico m√©dio): 4647.72

### 5. Random Forest

`RandomForestRegressor(n_estimators=50, criterion='squared_error', max_depth=5, random_state = 7)`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.89 / 0.85*
- Valida√ß√£o cruzada (15 folds):  85.23%
- RMSE (Raiz do erro quadr√°tico m√©dio): 4668.64
- 
### 6. XGBoost

`XGBRegressor(n_estimators=140, max_depth=4, learning_rate=0.05, objective="reg:squarederror", random_state=7)`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.91 / 0.85
- Valida√ß√£o cruzada (15 folds): 85.85%
- RMSE (Raiz do erro quadr√°tico m√©dio): 4621.63

### 7. LightGBM

LGBMRegressor(num_leaves=50, max_depth=4, learning_rate=0.1, n_estimators=50, random_state=7)`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.89 / 0.84*
- Valida√ß√£o cruzada (15 folds): 85.91%
- RMSE (Raiz do erro quadr√°tico m√©dio): 4782.14

### 8. CATBOOST

`CatBoostRegressor (iterations=230, learning_rate=0.05, depth = 6, random_state = 7, verbose=False)`

**Resultados:**
- R¬≤ (treino/teste): *aprox. 0.91 / 0.85*
- Valida√ß√£o cruzada (15 folds): 85.57%
- RMSE (Raiz do erro quadr√°tico m√©dio): 4594.31


## üèÜ Conclus√µes Principais

| Modelo            | R¬≤ Treino/Teste    |
|-------------------|--------------------|
| **CATBOOST**      | 0.91 / 0.85 ü•á     | 
| **LightGBM**      | 0.89 / 0.84 ü•à     | 
| **XGBoost**       | 0.91 / 0.85 ü•â     | 
| **Random Forest** | 0.85 / 0.83        |
| **√Årvore Decis√£o**| 0.81 / 0.78        | 
| **Regress√£o Linear** | 0.74 / 0.72      | 
| **SVR**           | 0.68 / 0.65        | 

**Principais Observa√ß√µes:**
- A vari√°vel `smoker` apresenta a maior correla√ß√£o positiva com o custo do seguro.
- Idade (`age`) e IMC (`bmi`) tamb√©m influenciam significativamente os custos.
- Modelos ensemble (Random Forest, XGBoost, LightGBM) apresentaram melhor capacidade de generaliza√ß√£o.

